{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExPred\n",
    "This notebook can be used generate parts of version 1, as well as version 2 of the prototypes for presentations of the attribution technique ExPred\n",
    "Required Input: Path to fever jsonl data set. (e.g. test.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import torch\n",
    "from src.expred import (seeding, ExpredInput,\n",
    "                        BertTokenizerWithSpans, ExpredConfig, Expred)\n",
    "from src.expred.models import (prepare_for_cl, train_evidence_classifier,\n",
    "                               train_mtl_token_identifier)\n",
    "from transformers import BertTokenizer\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to transform the input to the way the expred accepts\n",
    "def formatData(path_to_file, path_to_fever_docs):\n",
    "    data = []\n",
    "    with open(path_to_file, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        label = result.get('classification')\n",
    "        query = result.get('query').split()\n",
    "        for docs_id in result.get('docids'):\n",
    "            with open(f'{path_to_fever_docs}/{docs_id}', 'r') as json_file_2:\n",
    "                documents = list(json_file_2)\n",
    "                contexts = []\n",
    "                for doc in documents:\n",
    "                    contexts.append(doc.split())\n",
    "            data.append([label,query,contexts])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function with code from expred showcase\n",
    "def getExPredResult(data): \n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "    expred_config = ExpredConfig(\n",
    "        pretrained_dataset_name='fever',\n",
    "        base_dataset_name='fever',\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        load_from_pretrained=True)\n",
    "\n",
    "    # seeding\n",
    "    seeding(1234)\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = BertTokenizerWithSpans.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # create the model\n",
    "    expred = Expred.from_pretrained(expred_config)\n",
    "    expred.eval()\n",
    "\n",
    "    for data_point in data:\n",
    "        # print query and data to paste into figma template\n",
    "        print('Query: ', ' '.join(data_point[1]))\n",
    "        # flatten whole data \n",
    "        print('Whole data: ', ' '.join([item for sublist in data_point[2] for item in sublist]))\n",
    "        expred_input = ExpredInput(\n",
    "            queries = [data_point[1]],\n",
    "            docs = [data_point[2]],\n",
    "            labels = [data_point[0]],\n",
    "            config = expred_config,\n",
    "            ann_ids = ['spontan_1'],\n",
    "            span_tokenizer = tokenizer)\n",
    "        # don't forget to preprocess\n",
    "        expred_input.preprocess()\n",
    "\n",
    "        # the output is in the form of a dict:\n",
    "        expred_output = expred(expred_input)\n",
    "\n",
    "        # functions from ExPred\n",
    "        expred_preds_output = expred_input.get_decoded_exp_preds(expred_output)[0]\n",
    "        # optionally remove dots\n",
    "        # expred_preds_output = [i for i in expred_preds_output if i!=('.')]\n",
    "        print('Influencial tokens: ', ' '.join(expred_preds_output))\n",
    "        print('Classification: ',expred_input.get_decoded_cls_preds(expred_output)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'replace with path to jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-18-561b2ce06fe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;31m# Note that the highlighting was done manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'replace with path to jsonl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace with path to fever docs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgetExPredResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m<ipython-input-3-2e68eac5d133>\u001b[0m in \u001b[0;36mformatData\u001b[0;34m(path_to_file, path_to_fever_docs)\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mformatData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_fever_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mjson_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'replace with path to jsonl'"
     ]
    }
   ],
   "source": [
    "# After running this function the output can be used to copy/paste into ExPred Prototypes in Figma\n",
    "# Note that the highlighting was done manually\n",
    "\n",
    "data = formatData('replace with path to jsonl', 'replace with path to fever docs')\n",
    "getExPredResult(data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
